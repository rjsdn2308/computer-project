2. 프로젝트 내용
2.1 서론
최근 초등학교 저학년 아이들을 둔 부모들의 온라인 커뮤니티를 살펴보면,“아이들이 과일이 어디에서 자라는지 잘 모른다”, “마트에서 바로 나오는 줄 안다”는 글에 공감을 많이 하는 글을 보고 아이디어가 떠올랐으며
과일의 모양, 성장 과정, 재배 환경을 자연스럽게 배울 기회가 적어지면서 과일·식물 학습이 실생활과 분리되고 있는 현상이 일어난거 같다.
이에 따라 본 프로젝트는 아이들이 과일의 종류·특징·자라는 방식을 쉽고 재미있게 배울 수 있는 유아 친화형 교육 도구를 만드는 것을 목표로 한다.

프로젝트의 핵심은 두 가지이다.
1.이미지를 통한 과일 인식(CV)
2.아이 눈높이 설명 + 퀴즈를 제공하는 LLM 기반 챗봇
이를 결합한 앱 형태로,아이들이 직접 과일 사진을 찍고,
“이 과일은 무엇이고 어디에서 자라는지” 자연스럽게 학습할 수 있다.

2.2 추진 배경 (자료 조사 및 요구 분석)
2.2.1 개발 배경 및 필요성
아이들이 과일을 마주할 기회는 많지만, 정작 그 과일이 땅·나무·덩굴 중 어디에서 자라는지, 또 수확되기 전 모습은 접할 일이 거의 없다.
부모 커뮤니티와 교육 블로그 등에서 다음과 같은 필요성이 나타났다.
“아이에게 수박이 땅에서 자란다고 설명해도 실제 모습을 보여주기 어렵다.”
“사과가 나무에서 열린다는 개념을 잘 모른다.”
“마트 상품으로만 과일을 인식하는 경향이 있다.”
이에 따라 아이들이 스스로 찍은 사진을 기반으로 직접 탐구하고 배우는 경험형 학습도구의 필요성이 증가하고 있다.
이 프로젝트는 이러한 문제를 해결하기 위해:
*과일 사진을 분석해주는 CV 기술
*아이 눈높이 설명을 제공하는 LLM
*O/X 퀴즈를 통한 학습 강화
를 하나의 앱으로 통합하였다.

2.2.2 선행 기술 및 사례 분석
(1) 과일 인식(CV) 기반 서비스
Fruits-360 등과 같은 공개 데이터셋 기반 연구는 존재하나 대부분 연구용 데이터로, 실제 유아 학습 도구는 매우 제한적
식별 정도는 가능하지만 “수확 전 모습”, “자라는 방식(tree/ground/vine)”까지 안내하는 서비스는 드문 편

(2) 교육용 LLM 활용 사례
GPT API를 이용한 교육용 Q&A 서비스는 증가하는 추세
그러나 유아 맞춤 말투 + 간단한 설명 + OX 퀴즈까지 통합한 사례는 거의 없음
대부분의 LLM 챗봇은 어린이에게 너무 어렵거나 장문 위주의 설명 제공

(3) 본 프로젝트의 차별성
1.CV와 LLM을 결합한 유아 맞춤형 앱
2.아이에게 쉬운 말투·짧은 문장·친절한 안내 사용
3.수확 전 과일 이미지 제공 (시각 기반 학습 강화)
4.OX 퀴즈까지 포함한 반복 학습 구조
5.파스텔 톤 색상 및 단순 UI로 유아 친화적 환경 제공

2.2.3 선행 기술 한계 및 개선점
기존 한계 -> 본 프로젝트 개선 내용
과일 데이터셋이 연구용에 국한됨 -> 직접 수집한 실제 사진 기반 과일 인식 모델 구축
어린이에게 설명하기 어려운 LLM 말투 -> 유아 수준에 맞춘 부드러운 설명 프롬프트 설계
단순한 이미지 분류만 제공 -> 자라는 방식(tree/ground/vine) + 수확 전 이미지 + 설명 제공
학습 요소 부족 -> O/X 퀴즈, 아이 눈높이 감성 재작성 기능 포함

2.3 목표 및 내용
2.3.1 프로젝트 목표
사진을 기반으로 과일 종류 자동 인식
과일이 어디에서 자라는지·어떤 모습으로 자라는지 학습 지원
LLM을 활용하여 아이 눈높이 설명 제공
간단한 과일 O/X 퀴즈 제공
파스텔 기반 UI를 갖춘 유아 친화적 학습 앱 제작

2.3.2 개발 범위
구분                    내용
과일 이미지 분석(CV)	ResNet18 기반 과일 분류 모델 구현
LLM 기반 설명 생성	    OpenAI API 기반 유아용 설명 생성
퀴즈 생성 엔진	        O/X 과일 퀴즈 생성 및 정답 판단
UI/UX	              Gradio 기반 유아 친화적 인터페이스
데이터 구조	            fruit_meta.json 기반 정보 관리

2.3.3 시스템 구조 블록 다이어그램
사용자 → 과일 사진 업로드 → CV 모델 → 과일 종류/정보 →  
LLM 설명 생성 → 유아용 말투로 설명 → 사용자 학습

2.3.4 시퀀스 다이어그램
User → Web UI → 사진 업로드
       ↓
CV 모델 분석 → 과일 종류 예측
       ↓
메타 정보 조회 → grow_type / 수확 이미지
       ↓
LLM → 아이에게 맞춘 설명 생성
       ↓
UI에 결과 출력

2.3.5 개발 환경 및 구현 결과
개발 환경
Python 3.10
PyTorch (ResNet18)
Gradio
OpenAI API
JSON 기반 메타데이터 구조

주요 기능 구현 결과
과일 인식 모델 학습(apple, banana, strawberry)
수확 전 과일 이미지 연결 기능 구현
아이 맞춤형 설명 생성 LLM 프롬프트 구축
유아 친화적 UI (파스텔 기반 CSS)
과일 O/X 퀴즈 기능 정상 작동
챗봇 모드에서 자연스러운 아이 눈높이 대화 가능
CV+LLM 결합 흐름 정상 동작

2.3.6 문제점 및 한계점
본 프로젝트는 데모 앱 형태로 구현되었으며, 다음과 같은 한계점이 존재한다.

1.과일 이름이 같아도 국가/종류에 따라 모양이 다른 문제
예: 서양 사과와 동양 사과의 모양, 크기, 색이 다름
동일한 과일 이름이지만 지역·품종마다 형태 차이가 크기 때문에 모델의 일반화 능력이 아직 충분하지 않다.
2.과일 사진 데이터 부족 문제
과일은 COCO나 ImageNet처럼 대규모로 정제된 공개 데이터가 드물다.
저작권이 없는 데이터를 직접 수집해야 했는데 수집 시간 + 정제 과정이 오래 걸림
결과적으로 현재 모델은 소수의 과일만 지원하는 데모 수준이다.
3.실제 환경 이미지와의 차이
실외 촬영 사진·흐린 조도·부분 가려짐 등 다양한 촬영 환경을 반영한 데이터 부족
4.LLM 기반 설명 비용 문제
LLM 호출 비용 → 넓은 사용자층을 고려한 무료 서비스로는 어려움
캐싱/경량 모델 적용 등의 보완 필요

2.4 기대 효과
유아들이 사진을 찍으며 스스로 탐구하는 “경험형 학습” 가능
과일이 자라는 방식·모습을 자연스럽게 이해하도록 도움
부모·교사도 쉽게 설명할 수 있어 교육 효율 향상
실제 교육 현장(유치원/초등 저학년)에서도 활용 가능성 높음
CV + LLM 결합 학습 도구라는 기술적 확장성 확보

2.6 역할 분담

1. 강민수: 
CV 모델 개발 및 앱 연동 총괄
과일 이미지 데이터 수집·정제
ResNet18 기반 분류 모델 학습 및 정확도 점검
CV 모델과 Gradio UI 연동
수확 전 과일 이미지 매핑 및 fruit_meta.json 구조 설계
2. 김건우:
LLM 기능 구현 및 유아 친화형 대화 설계
아이 맞춤형 말투/길이/설명 방식을 위한 LLM 프롬프트 설계
과일 OX 퀴즈 생성·정답 분석 기능 개발
과일 Q&A 챗봇 자연스러운 답변 흐름 구축
CV 결과 기반 상세 설명 생성 기능 연결
3. 이준성:
전체 앱 구조·UI/UX 및 기능 통합 담당
Gradio 기반 전체 UI 구성 및 파스텔 톤 디자인 적용
CV–LLM–퀴즈 기능 종합 통합 및 상태 관리(State) 구성
이미지 분석/설명/대화 흐름 연결 로직 개발
앱 배포용 구조 정리 및 최종 프로젝트 통합

2.7 참고문헌
Mureșan & Oltean, Fruit recognition from images using deep learning, 2017
Fruits-360 Dataset, Kaggle, 2024
Yang et al., Lightweight and Efficient Deep Learning Models for Fruit Classification, 2024
OpenAI API Documentation, 2025
Gradio Documentation, 2025