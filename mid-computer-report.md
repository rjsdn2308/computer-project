# 📚 통합 LLM 프로젝트 보고서 (과일 유아교육 LLM + 제스처 스마트 제어 LLM)

본 문서는 업로드된 자료 중 **두 가지 핵심 프로젝트**만을 정리한 단일 통합 문서입니다.

✅ **과일 유아교육 LLM (fruit_tutor.py / fruit_qa.py)**
✅ **제스처 기반 스마트 제어 LLM (gesture_control_demo.py)**

* 공통 실행 환경 (.env / 실행방법.txt)

여행 일정 추천 LLM 관련 내용은 모두 제거하여 **깔끔하고 두 프로젝트 중심으로 재구성**했습니다.

---

# 1. 프로젝트 개요

두 프로젝트 모두 **OpenAI LLM(GPT-4o-mini)**을 활용해 사용자 입력에 맞는 자연어 응답을 생성한다.
각 시스템은 도메인은 다르지만 공통적으로:

* 자연어 입력 처리
* 상황·연령대·맥락 기반 프롬프트 구성
* LLM 호출
* 사용자 친화적 출력 생성

의 구조를 따른다.

프로젝트 구성은 다음과 같다:

| 프로젝트              | 도메인       | 핵심 파일                           | 목적                           |
| ----------------- | --------- | ------------------------------- | ---------------------------- |
| 과일 유아교육 LLM       | 아동 교육     | `fruit_tutor.py`, `fruit_qa.py` | 과일 설명·Q&A를 아이 눈높이에 맞게 제공     |
| 제스처 기반 스마트 제어 LLM | IoT/스마트 홈 | `gesture_control_demo.py`       | 제스처·명령을 자연스러운 시스템 안내 문장으로 변환 |
| 공통 실행 환경          | API·런타임   | `.env`, `실행방법.txt`              | API Key 관리 및 실행 가이드          |

---

# 2. 과일 유아교육 LLM 시스템

(파일: `fruit_tutor.py`, `fruit_qa.py`)
출처: fileciteturn0file0

## 2.1 목적

* 어린이가 과일을 재미있게 배울 수 있도록 **쉬운 설명 + 이모지** 포함 컨텐츠 생성
* "아이의 연령대"에 따라 다른 수준의 설명 제공
* Q&A 기능을 통해 아이가 자유롭게 질문해도 자연스러운 답변 생성

## 2.2 주요 기능

### ● (1) 과일 설명 생성기 — fruit_tutor.py

* 입력: 과일 이름 + 아이 연령대
* 출력: 짧고 쉬운 설명 (이모지 포함)
* 포함 요소:

  * 과일 기초 정보
  * 재배 환경
  * 성장 과정
  * 영양소와 효과

### ● (2) 아이 질문 응답기 — fruit_qa.py

* 입력: 아이 질문 + 연령대
* 출력: 과하지 않은 쉬운 문장으로 답변
* 어려운 부분은 "아이 눈높이에 맞춰 자동으로 쉽게 설명"

## 2.3 실행 예시

```
과일 이름: strawberry
연령대: 유치원
→ "딸기는 땅 가까운 곳에서 자라요 🍓 작고 달콤해서 아이들이 많이 좋아해요!"
```

## 2.4 기술 구조 요약

```
입력 → 프롬프트 생성 → GPT-4o-mini 호출 → 설명/답변 생성
```

---

# 3. 제스처 기반 스마트 제어 LLM 시스템

(파일: `gesture_control_demo.py`)
출처: fileciteturn0file1

## 3.1 목적

손 제스처 + 명령을 입력하면 LLM이 자연스러운 **스마트홈 안내 메시지**를 생성하는 시스템.

## 3.2 주요 기능

* 제스처 라벨 입력 (예: ok, peace, fist)
* 명령 입력 (예: 음악 재생, 불 꺼줘)
* 언어 선택(ko/en)
* LLM이 "1~2문장"으로 사용자에게 말하듯 부드럽게 안내
* 이모지 사용 가능

## 3.3 예시

```
Gesture: peace
Command: 음악 재생
→ "음악을 켤게요 🎵 기분 좋은 시간 보내세요!"
```

## 3.4 기술 구조

```
입력(gesture + command) → 자연어 프롬프트 구성 → GPT-4o-mini 호출 → 자연스러운 안내문 생성
```

## 3.5 확장성

* HaGRID 기반 제스처 데이터 예시 코드 포함
* YOLO, MediaPipe 등 실제 제스처 인식 모델과 연동 가능
* 스마트홈 제어 시스템으로 확장 가능

---

# 4. 공통 실행 환경

## 4.1 .env 파일

출처: fileciteturn0file2

### ● 포함 항목

```
OPENAI_API_KEY=...
HUGGINGFACEHUB_API_TOKEN=...
```

### ● 역할

* 두 프로젝트 모두 OpenAI API 호출 필요
* API Key를 코드와 분리해 안전하게 관리

---

# 4.2 실행 방법

출처: fileciteturn0file5

## ● 공통 설치

```
pip install openai python-dotenv
```

(제스처 시스템은 별도 설치 불필요, Flask 사용 없음)

## ● 프로젝트 실행 명령

### 과일 유아교육 LLM

```
python fruit_tutor.py
python fruit_qa.py
```

### 제스처 기반 스마트 제어 LLM

```
python gesture_control_demo.py
```

---

# 5. 결론

본 문서는 **과일 유아교육 LLM**과 **제스처 기반 스마트 제어 LLM** 두 개의 프로젝트를 중심으로 재구성되었으며, 두 시스템은 다음 공통점을 갖는다:

* LLM 기반 자연어 생성
* 사용자 친화적 프롬프트 설계
* .env 기반 API Key 관리
* 텍스트 기반 인터랙션 중심 구조

두 프로젝트는 교육·IoT 분야에서 활용 가능성이 높으며, 멀티모달(Vision) 모델과 결합 시 더 강력한 서비스로 확장할 수 있다.


